{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbb09f97",
   "metadata": {},
   "source": [
    "## 0. 라이브러리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "903e0a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from transformers import BertTokenizer, TFBertForSequenceClassification, TFBertModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import json\n",
    "from soynlp.normalizer import *\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07cb9271",
   "metadata": {},
   "source": [
    "## 1. 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ff8b41e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>conversation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>idx</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>일반 대화</td>\n",
       "      <td>야 여행 가기 너무 좋은 날씨다\\n날씨 진짜 너무 좋아 **이는 일하기 싫을 날씨야...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>갈취 대화</td>\n",
       "      <td>사정이 있었어요 . 살려주세요 . 뒤진 사람들 중에 사정 없는 사람 없어 맞아 . ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>갈취 대화</td>\n",
       "      <td>배고프다 그러게 야 만원만 빌려줘봐 오늘도 ? 저번에도 만원 빌려가고 안 돌려 줬잖...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>갈취 대화</td>\n",
       "      <td>저기 실례지만 제가 휠체어를 타는 장애인이라서 아 혼자 휠체어 운전하시는게 어렵다고...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>직장 내 괴롭힘 대화</td>\n",
       "      <td>김 사원 낙하산이라는 소문이 있던데 ? 요즘 시대에도 낙하산이 있어요 ? 요즘 더 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4826</th>\n",
       "      <td>일반 대화</td>\n",
       "      <td>티비는 잘 안 보니?\\n티비 매일 보지\\n너는?\\n키키 요즘 핫한 스우파 안 보니?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4827</th>\n",
       "      <td>갈취 대화</td>\n",
       "      <td>이거 나이키 신상이네 ? 응 아빠가 사주셨어 우와 멋지네 근데 너랑은 별로 안어울린...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4828</th>\n",
       "      <td>직장 내 괴롭힘 대화</td>\n",
       "      <td>일처리를 어떻게 한거야 ! 기간 내에 상품이 못오면 그사이 손실은 어떻게 할거냐고 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4829</th>\n",
       "      <td>직장 내 괴롭힘 대화</td>\n",
       "      <td>어우 정대리 이번에도 참 글래머 스럽게 입고왔네 네 ? 지금 저한태 하신말이세요 ?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4830</th>\n",
       "      <td>협박 대화</td>\n",
       "      <td>전화 좀 그만하세요 . 당신이 배달앱 리뷰에 내 욕을 써놔서 내가 잘 다니던 직장에...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4830 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            class                                       conversation\n",
       "idx                                                                 \n",
       "1           일반 대화  야 여행 가기 너무 좋은 날씨다\\n날씨 진짜 너무 좋아 **이는 일하기 싫을 날씨야...\n",
       "2           갈취 대화  사정이 있었어요 . 살려주세요 . 뒤진 사람들 중에 사정 없는 사람 없어 맞아 . ...\n",
       "3           갈취 대화  배고프다 그러게 야 만원만 빌려줘봐 오늘도 ? 저번에도 만원 빌려가고 안 돌려 줬잖...\n",
       "4           갈취 대화  저기 실례지만 제가 휠체어를 타는 장애인이라서 아 혼자 휠체어 운전하시는게 어렵다고...\n",
       "5     직장 내 괴롭힘 대화  김 사원 낙하산이라는 소문이 있던데 ? 요즘 시대에도 낙하산이 있어요 ? 요즘 더 ...\n",
       "...           ...                                                ...\n",
       "4826        일반 대화  티비는 잘 안 보니?\\n티비 매일 보지\\n너는?\\n키키 요즘 핫한 스우파 안 보니?...\n",
       "4827        갈취 대화  이거 나이키 신상이네 ? 응 아빠가 사주셨어 우와 멋지네 근데 너랑은 별로 안어울린...\n",
       "4828  직장 내 괴롭힘 대화  일처리를 어떻게 한거야 ! 기간 내에 상품이 못오면 그사이 손실은 어떻게 할거냐고 ...\n",
       "4829  직장 내 괴롭힘 대화  어우 정대리 이번에도 참 글래머 스럽게 입고왔네 네 ? 지금 저한태 하신말이세요 ?...\n",
       "4830        협박 대화  전화 좀 그만하세요 . 당신이 배달앱 리뷰에 내 욕을 써놔서 내가 잘 다니던 직장에...\n",
       "\n",
       "[4830 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_path =\"~/aiffel/dktc/data2/train0.csv\"\n",
    "train_data = pd.read_csv(train_data_path,index_col=0)\n",
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec06ff1",
   "metadata": {},
   "source": [
    "## 2. 데이터 준비 (Data preparation)\n",
    "### 2.1-1 전처리 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c4c27b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentence(sentence):\n",
    "    # synolp\n",
    "    emoticon_normalize(sentence)\n",
    "    repeat_normalize(sentence)\n",
    "    #sentence = re.sub(r'[^\\w\\s]', '', sentence)\n",
    "    # base preprocess\n",
    "    sentence = re.sub(r'([^a-zA-Zㄱ-ㅎ가-힣?.!,])', \" \", sentence)\n",
    "    sentence = re.sub(r'!+', '!', sentence)\n",
    "    sentence = re.sub(r'\\?+', '?', sentence)\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
    "    # 엔터 구분 (\\n)\n",
    "    sentence = sentence.replace(\"\\n\", \"<EOL>\")\n",
    "    sentence = sentence.strip()\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e810a0",
   "metadata": {},
   "source": [
    "### 2.1-2 전처리 함수 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e45ca13e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4830/4830 [00:01<00:00, 3199.34it/s]\n"
     ]
    }
   ],
   "source": [
    "# 학습할 문장이 담길 배열\n",
    "sentences = []\n",
    "\n",
    "for val in tqdm(train_data['conversation']):\n",
    "    sentences.append(preprocess_sentence(val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db93310",
   "metadata": {},
   "source": [
    "### 2.2 최대 길이 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2466d8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 250"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0589e6",
   "metadata": {},
   "source": [
    "### 2.3 class(label) 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f774d6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4830"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "CLASS_NAMES = ['협박 대화', '갈취 대화', '직장 내 괴롭힘 대화', '기타 괴롭힘 대화','일반 대화']\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(CLASS_NAMES)\n",
    "\n",
    "train_data['class'] = encoder.transform(train_data['class'])\n",
    "labels = train_data['class']\n",
    "\n",
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ffc3cca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class mapping: {'협박 대화': 4, '갈취 대화': 0, '직장 내 괴롭힘 대화': 3, '기타 괴롭힘 대화': 1, '일반 대화': 2}\n"
     ]
    }
   ],
   "source": [
    "class_mapping = {class_name: encoder.transform([class_name])[0] for class_name in CLASS_NAMES}\n",
    "print(\"Class mapping:\", class_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea7b62f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_examples_to_features(examples, labels, max_seq_len, tokenizer):\n",
    "    \n",
    "    input_ids, attention_masks, token_type_ids, data_labels = [], [], [], []\n",
    "    \n",
    "    for example, label in tqdm(zip(examples, labels), total=len(examples)):\n",
    "        # input_id는 워드 임베딩을 위한 문장의 정수 인코딩\n",
    "        input_id = tokenizer.encode(example, \n",
    "                                    max_length=max_seq_len, \n",
    "                                    pad_to_max_length=True,\n",
    "                                   )\n",
    "        \n",
    "        # attention_mask는 실제 단어가 위치하면 1, 패딩의 위치에는 0인 시퀀스\n",
    "        padding_count = input_id.count(tokenizer.pad_token_id)\n",
    "        attention_mask = [1] * (max_seq_len - padding_count) + [0] * padding_count\n",
    "        \n",
    "        # token_type_id은 세그먼트 인코딩\n",
    "        token_type_id = [0] * max_seq_len\n",
    "        \n",
    "        assert len(input_id) == max_seq_len, \"Error with input length {} vs {}\".format(len(input_id), max_seq_len)\n",
    "        assert len(attention_mask) == max_seq_len, \"Error with attention mask length {} vs {}\".format(len(attention_mask), max_seq_len)\n",
    "        assert len(token_type_id) == max_seq_len, \"Error with token type length {} vs {}\".format(len(token_type_id), max_seq_len)\n",
    "        \n",
    "        input_ids.append(input_id)\n",
    "        attention_masks.append(attention_mask)\n",
    "        token_type_ids.append(token_type_id)\n",
    "        data_labels.append(label)\n",
    "    \n",
    "    input_ids = np.array(input_ids, dtype=int)\n",
    "    attention_masks = np.array(attention_masks, dtype=int)\n",
    "    token_type_ids = np.array(token_type_ids, dtype=int)\n",
    "    \n",
    "    data_labels = np.asarray(data_labels, dtype=np.int32)\n",
    "    \n",
    "    return (input_ids, attention_masks, token_type_ids), data_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3649ea",
   "metadata": {},
   "source": [
    "### 2.4 train-val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5cda92e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentences, val_sentences, train_labels, val_labels = train_test_split(\n",
    "    sentences, labels, test_size=0.2, random_state=42, stratify=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f270135e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before data augmentation:  3864\n",
      "after data augmentation:  11592\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>idx</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>김비서 오늘 스케줄 어떻게 되지 ? 네 오전에 바이어 미팅있고 점심후엔 임원회의 예...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1779</th>\n",
       "      <td>이거 빨리 끝내고 일해야겠다 ㅎ 넌 몇 시 출근 ? 난 새벽 시 반 . . . 울고...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3214</th>\n",
       "      <td>김 과장 내가 부탁한 자료는 어떻게 된거야 ? 아 네 부장님 아직 하고 있습니다 ....</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4225</th>\n",
       "      <td>학생 이것 좀 도와줄 수 있어 ? 네 . ? 어떤 아니 우리가 밖에서 뭘 하는데 밖...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>내가 지난번에 말한대로 좋게 말할 때 시키는대로 해 . 왜그래 . 나는 못하겠어 ....</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2779</th>\n",
       "      <td>야 술 받으라고 ! 죄송합니다 . 한 잔 받겠습니다 . 너는 어째 회사 안이나 밖이...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2786</th>\n",
       "      <td>이거 할인 된다면서요 확인해보겠습니다 아까 저 시람은 할인 해주던데 네 저 손님은 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2932</th>\n",
       "      <td>지민이 포기해 . 애초에 너희 어울리지 않아 . 그건 지민이랑 제가 판단하는겁니다 ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4726</th>\n",
       "      <td>우리 채영이가 발표해볼까 ? . 네 . 저의 꿈은 의사입니다 . 선생님 안들려요 ....</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1109</th>\n",
       "      <td>너네 부모님 무슨 일 하셔 ? 우리 부모님 떡볶이 가게 운영하셔 엥 ? 그럼 한 달...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11592 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sentence  class\n",
       "idx                                                           \n",
       "346   김비서 오늘 스케줄 어떻게 되지 ? 네 오전에 바이어 미팅있고 점심후엔 임원회의 예...      3\n",
       "1779  이거 빨리 끝내고 일해야겠다 ㅎ 넌 몇 시 출근 ? 난 새벽 시 반 . . . 울고...      2\n",
       "3214  김 과장 내가 부탁한 자료는 어떻게 된거야 ? 아 네 부장님 아직 하고 있습니다 ....      3\n",
       "4225  학생 이것 좀 도와줄 수 있어 ? 네 . ? 어떤 아니 우리가 밖에서 뭘 하는데 밖...      0\n",
       "295   내가 지난번에 말한대로 좋게 말할 때 시키는대로 해 . 왜그래 . 나는 못하겠어 ....      4\n",
       "...                                                 ...    ...\n",
       "2779  야 술 받으라고 ! 죄송합니다 . 한 잔 받겠습니다 . 너는 어째 회사 안이나 밖이...      3\n",
       "2786  이거 할인 된다면서요 확인해보겠습니다 아까 저 시람은 할인 해주던데 네 저 손님은 ...      1\n",
       "2932  지민이 포기해 . 애초에 너희 어울리지 않아 . 그건 지민이랑 제가 판단하는겁니다 ...      4\n",
       "4726  우리 채영이가 발표해볼까 ? . 네 . 저의 꿈은 의사입니다 . 선생님 안들려요 ....      1\n",
       "1109  너네 부모님 무슨 일 하셔 ? 우리 부모님 떡볶이 가게 운영하셔 엥 ? 그럼 한 달...      1\n",
       "\n",
       "[11592 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train data 증강\n",
    "\n",
    "def random_deletion(words, p=0.3):\n",
    "    if len(words) == 1:\n",
    "        return words\n",
    "\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        r = random.uniform(0, 1)\n",
    "        if r > p:\n",
    "            new_words.append(word)\n",
    "\n",
    "    if len(new_words) == 0:\n",
    "        rand_int = random.randint(0, len(words) - 1)\n",
    "        return [words[rand_int]]\n",
    "\n",
    "    return \"\".join(new_words)\n",
    "\n",
    "def swap_word(new_words):\n",
    "    random_idx_1 = random.randint(0, len(new_words) - 1)\n",
    "    random_idx_2 = random_idx_1\n",
    "    counter = 0\n",
    "\n",
    "    while random_idx_2 == random_idx_1:\n",
    "        random_idx_2 = random.randint(0, len(new_words) - 1)\n",
    "        counter += 1\n",
    "        if counter > 3:\n",
    "            return new_words\n",
    "\n",
    "    new_words[random_idx_1], new_words[random_idx_2] = (\n",
    "        new_words[random_idx_2],\n",
    "        new_words[random_idx_1],\n",
    "    )\n",
    "    return new_words\n",
    "\n",
    "\n",
    "def random_swap(words, n=3):\n",
    "    new_words = words.copy()\n",
    "    for _ in range(n):\n",
    "        new_words = swap_word(new_words)\n",
    "\n",
    "    return new_words\n",
    "\n",
    "\n",
    "print(\"before data augmentation: \", len(train_sentences))\n",
    "\n",
    "train_splted = pd.DataFrame({ \"sentence\": train_sentences, \"class\": train_labels })\n",
    "\n",
    "# random deletion\n",
    "train_splted_rd = train_splted.copy()\n",
    "train_splted_rd[\"sentence\"] = train_splted_rd[\"sentence\"].apply(random_deletion)\n",
    "\n",
    "# random swap\n",
    "train_splted_rs = train_splted.copy()\n",
    "\n",
    "# with data augmentation\n",
    "train_concated = pd.concat([train_splted , train_splted_rd , train_splted_rs])\n",
    "\n",
    "print(\"after data augmentation: \", len(train_concated))\n",
    "\n",
    "train_concated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "36c911db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11592\n"
     ]
    }
   ],
   "source": [
    "train_sentences, train_labels = train_concated[\"sentence\"], train_concated[\"class\"]\n",
    "print(len(train_sentences))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e467d2",
   "metadata": {},
   "source": [
    "## 3. 모델\n",
    "### 3.1-1 토크나이저 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b1295d35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BERT 토크나이저와 모델 준비\n",
    "model_name = \"klue/bert-base\"\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "special_tokens_dict = {'additional_special_tokens': ['<EOL>']}\n",
    "tokenizer.add_special_tokens(special_tokens_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f8e5da5",
   "metadata": {},
   "source": [
    "### 3.1-2 토크나이저 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0e63b71b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/11592 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2211: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "100%|██████████| 11592/11592 [00:10<00:00, 1113.77it/s]\n",
      "100%|██████████| 966/966 [00:00<00:00, 1037.13it/s]\n"
     ]
    }
   ],
   "source": [
    "# 데이터셋을 BERT 입력 형식으로 변환\n",
    "X_train, y_train = convert_examples_to_features(\n",
    "    train_sentences, train_labels, \n",
    "    max_seq_len=MAX_LEN, tokenizer=tokenizer\n",
    ")\n",
    "X_valid, y_valid = convert_examples_to_features(\n",
    "    val_sentences, val_labels, \n",
    "    max_seq_len=MAX_LEN, tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "# train_encodings = tokenizer(train_sentences, truncation=True, padding=True, max_length=MAX_LEN) # 뒤쪽에 패딩\n",
    "# val_encodings = tokenizer(val_sentences, truncation=True, padding=True, max_length=MAX_LEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfee109c",
   "metadata": {},
   "source": [
    "### 3.2 모델 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c1a36900",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TFBertForMultiClassClassification(tf.keras.Model):\n",
    "    def __init__(self, model_name, num_classes, dropout_rate=0.1):\n",
    "        super(TFBertForMultiClassClassification, self).__init__()\n",
    "        self.bert = TFBertModel.from_pretrained(model_name, from_pt=True)\n",
    "        self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
    "        self.classifier = tf.keras.layers.Dense(num_classes,\n",
    "                                                kernel_initializer=tf.keras.initializers.TruncatedNormal(0.02),\n",
    "                                                kernel_regularizer=l2(0.01),\n",
    "                                                activation='softmax',\n",
    "                                                name='classifier')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        input_ids, attention_mask, token_type_ids = inputs\n",
    "        outputs = self.bert(input_ids=input_ids,\n",
    "                            attention_mask=attention_mask,\n",
    "                            token_type_ids=token_type_ids)\n",
    "        cls_token = outputs[1]\n",
    "        dropped = self.dropout(cls_token)\n",
    "        prediction = self.classifier(dropped)\n",
    "        return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4333fb7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'bert.embeddings.position_ids', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "model = TFBertForMultiClassClassification(model_name, num_classes=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "085bb5bf",
   "metadata": {},
   "source": [
    "### 3.3 파라미터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bba96188",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "lr = 5e-5\n",
    "EPOCH = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f106e58c",
   "metadata": {},
   "source": [
    "### 3.4 TF 데이터셋 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f0951488",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorFlow 데이터셋 생성\n",
    "# train_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "#     dict(X_train),\n",
    "#     y_train\n",
    "# )).shuffle(100).batch(BATCH_SIZE)\n",
    "\n",
    "# val_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "#     dict(X_valid),\n",
    "#     y_valid\n",
    "# )).batch(BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e13b02",
   "metadata": {},
   "source": [
    "### 3.5 모델 컴파일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c0f6ab6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2b7fd1",
   "metadata": {},
   "source": [
    "### 3.6 모델 훈련"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1c66a6",
   "metadata": {},
   "source": [
    "### 3.6-1 콜백 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ca122ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime \n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',    # 검증 손실을 모니터링\n",
    "    patience=2,            # 3 에포크 동안 개선되지 않으면 중지\n",
    "    restore_best_weights=True  # 최상의 가중치를 복원\n",
    ")\n",
    "\n",
    "now = datetime.datetime.now()\n",
    "time = now.strftime(\"%y-%m-%d %H:%M\")\n",
    "data_type = 0\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath=f'./models/klue_with_aug_weights_{data_type}_m250_{time}.keras',  # 모델 가중치를 저장할 파일 경로\n",
    "    monitor='val_loss',        # 검증 손실을 모니터링\n",
    "    save_best_only=True,       # 최상의 모델만 저장\n",
    "    save_weights_only=True,    # 저장 (가중치)\n",
    "    mode='min',                # 'val_loss'가 최소일 때 저장\n",
    "    verbose=1                  # 저장 시 로그 출력\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4202bc",
   "metadata": {},
   "source": [
    "### 3.6-2 모델 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "270e2752",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "363/363 [==============================] - 613s 2s/step - loss: 0.3987 - accuracy: 0.8888 - val_loss: 0.3163 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.31630, saving model to ./models/klue_with_aug_weights_0_m250_24-06-26 05:54.keras\n",
      "Epoch 2/10\n",
      "363/363 [==============================] - 596s 2s/step - loss: 0.1563 - accuracy: 0.9767 - val_loss: 0.3850 - val_accuracy: 0.9182\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.31630\n",
      "Epoch 3/10\n",
      "363/363 [==============================] - 596s 2s/step - loss: 0.1099 - accuracy: 0.9898 - val_loss: 0.4133 - val_accuracy: 0.9110\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.31630\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7854e8065160>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train, y_train, \n",
    "    validation_data=(X_valid, y_valid),\n",
    "    epochs=EPOCH,\n",
    "    callbacks=[early_stopping, checkpoint]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909f0430",
   "metadata": {},
   "source": [
    "### 3.7 모델 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4facb6d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 17s 533ms/step - loss: 0.3163 - accuracy: 0.9286\n",
      "평가 결과: [0.3162969946861267, 0.9285714030265808]\n"
     ]
    }
   ],
   "source": [
    "# 모델 평가\n",
    "evaluation = model.evaluate(X_valid, y_valid)\n",
    "print(\"평가 결과:\", evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4110f408",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, f1_score, confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np \n",
    "\n",
    "def score(model, val):\n",
    "    X, y = val\n",
    "    # 실제 예측값 생성\n",
    "    real_predictions = model.predict(X)\n",
    "\n",
    "    # 예측값을 레이블로 변환\n",
    "    real_predicted_labels = np.argmax(real_predictions, axis=1)\n",
    "\n",
    "    # 정확도 계산\n",
    "    real_accuracy = accuracy_score(y, real_predicted_labels)\n",
    "    print(f\"Real Accuracy: {real_accuracy:.4f}\")\n",
    "\n",
    "    # 분류 보고서 생성\n",
    "    real_report = classification_report(y, real_predicted_labels, target_names=[f\"Class {i}\" for i in range(5)])\n",
    "    print(real_report)\n",
    "\n",
    "    # F1 스코어 계산\n",
    "    real_f1 = f1_score(y, real_predicted_labels, average='weighted')\n",
    "    print(f\"\\nWeighted F1 Score (based on real predictions): {real_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0a29c3df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real Accuracy: 0.9286\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.87      0.85      0.86       196\n",
      "     Class 1       0.89      0.92      0.90       219\n",
      "     Class 2       1.00      1.00      1.00       176\n",
      "     Class 3       0.98      0.97      0.98       196\n",
      "     Class 4       0.91      0.91      0.91       179\n",
      "\n",
      "    accuracy                           0.93       966\n",
      "   macro avg       0.93      0.93      0.93       966\n",
      "weighted avg       0.93      0.93      0.93       966\n",
      "\n",
      "\n",
      "Weighted F1 Score (based on real predictions): 0.9285\n"
     ]
    }
   ],
   "source": [
    "score(model, (X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4317e2ca",
   "metadata": {},
   "source": [
    "## 4. 모델 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ca874dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "test_data_path = \"/aiffel/aiffel/dktc/data/test.json\"\n",
    "test = pd.read_json(test_data_path).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5e125c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "test_predict = []\n",
    "\n",
    "for idx, value in test.iterrows():\n",
    "\n",
    "    test_sentence = value[\"text\"]\n",
    "    \n",
    "    test_encodings = tokenizer(test_sentence, truncation=True, padding=\"max_length\", max_length=MAX_LEN, return_tensors=\"tf\")\n",
    "\n",
    "    test_predictions = model.predict(\n",
    "        (test_encodings[\"input_ids\"],\n",
    "         test_encodings[\"attention_mask\"],\n",
    "         test_encodings[\"token_type_ids\"])\n",
    "    )\n",
    "    test_class_probabilities = tf.nn.softmax(test_predictions, axis=-1).numpy() # [[0.13297564 0.8358507  0.00801584 0.02315779]]\n",
    "    test_predicted_class = np.argmax(test_class_probabilities, axis=1) # [ 1 ]\n",
    "    test_predict.append(test_predicted_class[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e95edf06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 2)\n",
      "  file_name  class\n",
      "0     t_000      1\n",
      "1     t_001      2\n",
      "2     t_002      2\n",
      "3     t_003      3\n",
      "4     t_004      3\n"
     ]
    }
   ],
   "source": [
    "# {'협박 대화': 4, '갈취 대화': 0, '직장 내 괴롭힘 대화': 3, '기타 괴롭힘 대화': 1, '일반 대화': 2}\n",
    "#   협박 대화 : 0,  갈취 대화 : 1,  직장 내 괴롭힘 대화 : 2,  기타 괴롭힘 대화 : 3,  일반 대화 : 4\n",
    "def labelnum_to_text(x):\n",
    "    if x == 0:\n",
    "        return '01'\n",
    "    if x == 1:\n",
    "        return '03'\n",
    "    if x == 2:\n",
    "        return '04'\n",
    "    if x == 3:\n",
    "        return '02'\n",
    "    if x == 4:\n",
    "        return '00'\n",
    "\n",
    "import datetime\n",
    "    \n",
    "submission = pd.read_csv(\"../data/new_submission.csv\")\n",
    "submission[\"class\"] = [ labelnum_to_text(pred) for pred in test_predict ]\n",
    "\n",
    "now = datetime.datetime.now()\n",
    "filename = now.strftime(\"../sub/submission %y-%m-%d %H:%M.csv\")\n",
    "\n",
    "submission.to_csv(filename, index=False)\n",
    "submit_file = pd.read_csv(filename)\n",
    "\n",
    "print(submit_file.shape)\n",
    "print(submit_file.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "548223e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# submission "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
