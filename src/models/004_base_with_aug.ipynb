{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2cba135",
   "metadata": {},
   "source": [
    "## 0. 라이브러리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b4e5042",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from transformers import BertTokenizer, TFBertForSequenceClassification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import json\n",
    "from soynlp.normalizer import *\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8145a7e",
   "metadata": {},
   "source": [
    "## 1. 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f460d19c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>conversation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>idx</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>일반 대화</td>\n",
       "      <td>야 여행 가기 너무 좋은 날씨다\\n날씨 진짜 너무 좋아 **이는 일하기 싫을 날씨야...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>갈취 대화</td>\n",
       "      <td>사정이 있었어요 . 살려주세요 . 뒤진 사람들 중에 사정 없는 사람 없어 맞아 . ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>갈취 대화</td>\n",
       "      <td>배고프다 그러게 야 만원만 빌려줘봐 오늘도 ? 저번에도 만원 빌려가고 안 돌려 줬잖...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>갈취 대화</td>\n",
       "      <td>저기 실례지만 제가 휠체어를 타는 장애인이라서 아 혼자 휠체어 운전하시는게 어렵다고...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>직장 내 괴롭힘 대화</td>\n",
       "      <td>김 사원 낙하산이라는 소문이 있던데 ? 요즘 시대에도 낙하산이 있어요 ? 요즘 더 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4826</th>\n",
       "      <td>일반 대화</td>\n",
       "      <td>티비는 잘 안 보니?\\n티비 매일 보지\\n너는?\\n키키 요즘 핫한 스우파 안 보니?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4827</th>\n",
       "      <td>갈취 대화</td>\n",
       "      <td>이거 나이키 신상이네 ? 응 아빠가 사주셨어 우와 멋지네 근데 너랑은 별로 안어울린...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4828</th>\n",
       "      <td>직장 내 괴롭힘 대화</td>\n",
       "      <td>일처리를 어떻게 한거야 ! 기간 내에 상품이 못오면 그사이 손실은 어떻게 할거냐고 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4829</th>\n",
       "      <td>직장 내 괴롭힘 대화</td>\n",
       "      <td>어우 정대리 이번에도 참 글래머 스럽게 입고왔네 네 ? 지금 저한태 하신말이세요 ?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4830</th>\n",
       "      <td>협박 대화</td>\n",
       "      <td>전화 좀 그만하세요 . 당신이 배달앱 리뷰에 내 욕을 써놔서 내가 잘 다니던 직장에...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4830 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            class                                       conversation\n",
       "idx                                                                 \n",
       "1           일반 대화  야 여행 가기 너무 좋은 날씨다\\n날씨 진짜 너무 좋아 **이는 일하기 싫을 날씨야...\n",
       "2           갈취 대화  사정이 있었어요 . 살려주세요 . 뒤진 사람들 중에 사정 없는 사람 없어 맞아 . ...\n",
       "3           갈취 대화  배고프다 그러게 야 만원만 빌려줘봐 오늘도 ? 저번에도 만원 빌려가고 안 돌려 줬잖...\n",
       "4           갈취 대화  저기 실례지만 제가 휠체어를 타는 장애인이라서 아 혼자 휠체어 운전하시는게 어렵다고...\n",
       "5     직장 내 괴롭힘 대화  김 사원 낙하산이라는 소문이 있던데 ? 요즘 시대에도 낙하산이 있어요 ? 요즘 더 ...\n",
       "...           ...                                                ...\n",
       "4826        일반 대화  티비는 잘 안 보니?\\n티비 매일 보지\\n너는?\\n키키 요즘 핫한 스우파 안 보니?...\n",
       "4827        갈취 대화  이거 나이키 신상이네 ? 응 아빠가 사주셨어 우와 멋지네 근데 너랑은 별로 안어울린...\n",
       "4828  직장 내 괴롭힘 대화  일처리를 어떻게 한거야 ! 기간 내에 상품이 못오면 그사이 손실은 어떻게 할거냐고 ...\n",
       "4829  직장 내 괴롭힘 대화  어우 정대리 이번에도 참 글래머 스럽게 입고왔네 네 ? 지금 저한태 하신말이세요 ?...\n",
       "4830        협박 대화  전화 좀 그만하세요 . 당신이 배달앱 리뷰에 내 욕을 써놔서 내가 잘 다니던 직장에...\n",
       "\n",
       "[4830 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_path =\"~/aiffel/dktc/data2/train0.csv\"\n",
    "train_data = pd.read_csv(train_data_path,index_col=0)\n",
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52fc89e6",
   "metadata": {},
   "source": [
    "## 2. 데이터 준비 (Data preparation)\n",
    "### 2.1-1 전처리 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc8b82c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentence(sentence):\n",
    "    # synolp\n",
    "    emoticon_normalize(sentence)\n",
    "    repeat_normalize(sentence)\n",
    "    sentence = re.sub(r'[^\\w\\s]', '', sentence)\n",
    "    # base preprocess\n",
    "    sentence = re.sub(r'([^a-zA-Zㄱ-ㅎ가-힣?.!,])', \" \", sentence)\n",
    "    sentence = re.sub(r'!+', '!', sentence)\n",
    "    sentence = re.sub(r'\\?+', '?', sentence)\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
    "    # 엔터 구분 (\\n)\n",
    "    sentence = sentence.replace(\"\\n\", \" \")\n",
    "    sentence = sentence.strip()\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89eb3148",
   "metadata": {},
   "source": [
    "### 2.1-2 전처리 함수 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b71357b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4830/4830 [00:01<00:00, 3323.84it/s]\n"
     ]
    }
   ],
   "source": [
    "# 학습할 문장이 담길 배열\n",
    "sentences = []\n",
    "\n",
    "for val in tqdm(train_data['conversation']):\n",
    "    sentences.append(preprocess_sentence(val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6c6b12",
   "metadata": {},
   "source": [
    "### 2.2 최대 길이 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd7fb577",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5921beb2",
   "metadata": {},
   "source": [
    "### 2.3 class(label) 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10194d9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4830"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "CLASS_NAMES = ['협박 대화', '갈취 대화', '직장 내 괴롭힘 대화', '기타 괴롭힘 대화','일반 대화']\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(CLASS_NAMES)\n",
    "\n",
    "train_data['class'] = encoder.transform(train_data['class'])\n",
    "labels = train_data['class']\n",
    "\n",
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b347fbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class mapping: {'협박 대화': 4, '갈취 대화': 0, '직장 내 괴롭힘 대화': 3, '기타 괴롭힘 대화': 1, '일반 대화': 2}\n"
     ]
    }
   ],
   "source": [
    "class_mapping = {class_name: encoder.transform([class_name])[0] for class_name in CLASS_NAMES}\n",
    "print(\"Class mapping:\", class_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6e0010",
   "metadata": {},
   "source": [
    "### 2.4 train-val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4bd416ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentences, val_sentences, train_labels, val_labels = train_test_split(\n",
    "    sentences, labels, test_size=0.2, random_state=42, stratify=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e20af560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before data augmentation:  3864\n",
      "after data augmentation:  11592\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>idx</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>김비서 오늘 스케줄 어떻게 되지 네 오전에 바이어 미팅있고 점심후엔 임원회의 예정 ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1779</th>\n",
       "      <td>이거 빨리 끝내고 일해야겠다 ㅎ 넌 몇 시 출근 난 새벽 시 반 울고 싶다 오후에는...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3214</th>\n",
       "      <td>김 과장 내가 부탁한 자료는 어떻게 된거야 아 네 부장님 아직 하고 있습니다 내가 ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4225</th>\n",
       "      <td>학생 이것 좀 도와줄 수 있어 네 어떤 아니 우리가 밖에서 뭘 하는데 밖이 너무 추...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>내가 지난번에 말한대로 좋게 말할 때 시키는대로 해 왜그래 나는 못하겠어 야 그건 ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2779</th>\n",
       "      <td>야 술 받으라고 죄송합니다 한 잔 받겠습니다 너는 어째 회사 안이나 밖이나 똑같냐 ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2786</th>\n",
       "      <td>이거 할인 된다면서요 확인해보겠습니다 아까 저 시람은 할인 해주던데 네 저 손님은 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2932</th>\n",
       "      <td>지민이 포기해 애초에 너희 어울리지 않아 그건 지민이랑 제가 판단하는겁니다 글쎄 이...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4726</th>\n",
       "      <td>우리 채영이가 발표해볼까 네 저의 꿈은 의사입니다 선생님 안들려요 채영아 우리 큰 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1109</th>\n",
       "      <td>너네 부모님 무슨 일 하셔 우리 부모님 떡볶이 가게 운영하셔 엥 그럼 한 달 수입이...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11592 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sentence  class\n",
       "idx                                                           \n",
       "346   김비서 오늘 스케줄 어떻게 되지 네 오전에 바이어 미팅있고 점심후엔 임원회의 예정 ...      3\n",
       "1779  이거 빨리 끝내고 일해야겠다 ㅎ 넌 몇 시 출근 난 새벽 시 반 울고 싶다 오후에는...      2\n",
       "3214  김 과장 내가 부탁한 자료는 어떻게 된거야 아 네 부장님 아직 하고 있습니다 내가 ...      3\n",
       "4225  학생 이것 좀 도와줄 수 있어 네 어떤 아니 우리가 밖에서 뭘 하는데 밖이 너무 추...      0\n",
       "295   내가 지난번에 말한대로 좋게 말할 때 시키는대로 해 왜그래 나는 못하겠어 야 그건 ...      4\n",
       "...                                                 ...    ...\n",
       "2779  야 술 받으라고 죄송합니다 한 잔 받겠습니다 너는 어째 회사 안이나 밖이나 똑같냐 ...      3\n",
       "2786  이거 할인 된다면서요 확인해보겠습니다 아까 저 시람은 할인 해주던데 네 저 손님은 ...      1\n",
       "2932  지민이 포기해 애초에 너희 어울리지 않아 그건 지민이랑 제가 판단하는겁니다 글쎄 이...      4\n",
       "4726  우리 채영이가 발표해볼까 네 저의 꿈은 의사입니다 선생님 안들려요 채영아 우리 큰 ...      1\n",
       "1109  너네 부모님 무슨 일 하셔 우리 부모님 떡볶이 가게 운영하셔 엥 그럼 한 달 수입이...      1\n",
       "\n",
       "[11592 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train data 증강\n",
    "\n",
    "def random_deletion(words, p=0.3):\n",
    "    if len(words) == 1:\n",
    "        return words\n",
    "\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        r = random.uniform(0, 1)\n",
    "        if r > p:\n",
    "            new_words.append(word)\n",
    "\n",
    "    if len(new_words) == 0:\n",
    "        rand_int = random.randint(0, len(words) - 1)\n",
    "        return [words[rand_int]]\n",
    "\n",
    "    return \"\".join(new_words)\n",
    "\n",
    "def swap_word(new_words):\n",
    "    random_idx_1 = random.randint(0, len(new_words) - 1)\n",
    "    random_idx_2 = random_idx_1\n",
    "    counter = 0\n",
    "\n",
    "    while random_idx_2 == random_idx_1:\n",
    "        random_idx_2 = random.randint(0, len(new_words) - 1)\n",
    "        counter += 1\n",
    "        if counter > 3:\n",
    "            return new_words\n",
    "\n",
    "    new_words[random_idx_1], new_words[random_idx_2] = (\n",
    "        new_words[random_idx_2],\n",
    "        new_words[random_idx_1],\n",
    "    )\n",
    "    return new_words\n",
    "\n",
    "\n",
    "def random_swap(words, n=3):\n",
    "    new_words = words.copy()\n",
    "    for _ in range(n):\n",
    "        new_words = swap_word(new_words)\n",
    "\n",
    "    return new_words\n",
    "\n",
    "\n",
    "print(\"before data augmentation: \", len(train_sentences))\n",
    "\n",
    "train_splted = pd.DataFrame({ \"sentence\": train_sentences, \"class\": train_labels })\n",
    "\n",
    "# random deletion\n",
    "train_splted_rd = train_splted.copy()\n",
    "train_splted_rd[\"sentence\"] = train_splted_rd[\"sentence\"].apply(random_deletion)\n",
    "\n",
    "# random swap\n",
    "train_splted_rs = train_splted.copy()\n",
    "\n",
    "# with data augmentation\n",
    "train_concated = pd.concat([train_splted , train_splted_rd , train_splted_rs])\n",
    "\n",
    "print(\"after data augmentation: \", len(train_concated))\n",
    "\n",
    "train_concated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1c23142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx\n",
      "346     김비서 오늘 스케줄 어떻게 되지 네 오전에 바이어 미팅있고 점심후엔 임원회의 예정 ...\n",
      "1779    이거 빨리 끝내고 일해야겠다 ㅎ 넌 몇 시 출근 난 새벽 시 반 울고 싶다 오후에는...\n",
      "3214    김 과장 내가 부탁한 자료는 어떻게 된거야 아 네 부장님 아직 하고 있습니다 내가 ...\n",
      "4225    학생 이것 좀 도와줄 수 있어 네 어떤 아니 우리가 밖에서 뭘 하는데 밖이 너무 추...\n",
      "295     내가 지난번에 말한대로 좋게 말할 때 시키는대로 해 왜그래 나는 못하겠어 야 그건 ...\n",
      "Name: sentence, dtype: object\n"
     ]
    }
   ],
   "source": [
    "train_sentences, train_labels = train_concated[\"sentence\"], train_concated[\"class\"].values\n",
    "print(train_sentences[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2606f467",
   "metadata": {},
   "source": [
    "## 3. 모델\n",
    "### 3.1-1 토크나이저 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "256e2f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BERT 토크나이저와 모델 준비\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-multilingual-cased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72b3f84",
   "metadata": {},
   "source": [
    "### 3.1-2 토크나이저 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6775250b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋을 BERT 입력 형식으로 변환\n",
    "train_encodings = tokenizer(train_sentences.values.reshape(-1).tolist(), truncation=True, padding=True, max_length=MAX_LEN) # 뒤쪽에 패딩\n",
    "val_encodings = tokenizer(val_sentences, truncation=True, padding=True, max_length=MAX_LEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6b4538",
   "metadata": {},
   "source": [
    "### 3.2 모델 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "359ab660",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = TFBertForSequenceClassification.from_pretrained(\"bert-base-multilingual-cased\", num_labels=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9af4c46",
   "metadata": {},
   "source": [
    "### 3.3 파라미터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c44a9031",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "lr = 5e-5\n",
    "EPOCH = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3bc0cea",
   "metadata": {},
   "source": [
    "### 3.4 TF 데이터셋 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bfc75bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorFlow 데이터셋 생성\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(train_encodings),\n",
    "    train_labels\n",
    ")).shuffle(100).batch(BATCH_SIZE)\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(val_encodings),\n",
    "    val_labels\n",
    ")).batch(BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ad4e36",
   "metadata": {},
   "source": [
    "### 3.5 모델 컴파일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4b46e6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb7b5e63",
   "metadata": {},
   "source": [
    "### 3.6 모델 훈련"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9574ee",
   "metadata": {},
   "source": [
    "### 3.6-1 콜백 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ddf22302",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',    # 검증 손실을 모니터링\n",
    "    patience=2,            # 3 에포크 동안 개선되지 않으면 중지\n",
    "    restore_best_weights=True  # 최상의 가중치를 복원\n",
    ")\n",
    "\n",
    "import datetime\n",
    "\n",
    "now = datetime.datetime.now()\n",
    "time = now.strftime(\"%y-%m-%d %H:%M\")\n",
    "data_type = 0\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath=f'./models/klue_no_aug_weights_{data_type}_{time}.keras',  # 모델 가중치를 저장할 파일 경로\n",
    "    monitor='val_loss',        # 검증 손실을 모니터링\n",
    "    save_best_only=True,       # 최상의 모델만 저장\n",
    "    save_weights_only=True,   # 저장 (가중치)\n",
    "    mode='min',                # 'val_loss'가 최소일 때 저장\n",
    "    verbose=1                  # 저장 시 로그 출력\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc635ba",
   "metadata": {},
   "source": [
    "### 3.6-2 모델 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "da5e66b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "725/725 [==============================] - 795s 1s/step - loss: 0.6929 - accuracy: 0.7382 - val_loss: 0.4128 - val_accuracy: 0.8551\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.41277, saving model to ./models/klue_no_aug_weights_0_24-06-26 08:09.keras\n",
      "Epoch 2/10\n",
      "725/725 [==============================] - 779s 1s/step - loss: 0.3107 - accuracy: 0.8947 - val_loss: 0.3825 - val_accuracy: 0.8861\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.41277 to 0.38247, saving model to ./models/klue_no_aug_weights_0_24-06-26 08:09.keras\n",
      "Epoch 3/10\n",
      "725/725 [==============================] - 779s 1s/step - loss: 0.1866 - accuracy: 0.9375 - val_loss: 0.4127 - val_accuracy: 0.8882\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.38247\n",
      "Epoch 4/10\n",
      "725/725 [==============================] - 779s 1s/step - loss: 0.1335 - accuracy: 0.9574 - val_loss: 0.4411 - val_accuracy: 0.8892\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.38247\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x79447870d130>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_dataset, \n",
    "    validation_data=val_dataset,\n",
    "    epochs=EPOCH,\n",
    "    callbacks=[early_stopping, checkpoint]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81e20a7",
   "metadata": {},
   "source": [
    "### 3.7 모델 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0bd4b23a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61/61 [==============================] - 21s 344ms/step - loss: 0.3825 - accuracy: 0.8861\n",
      "평가 결과: [0.38247063755989075, 0.8861283659934998]\n"
     ]
    }
   ],
   "source": [
    "# 모델 평가\n",
    "evaluation = model.evaluate(val_dataset)\n",
    "print(\"평가 결과:\", evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5a389381",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, f1_score, confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np \n",
    "\n",
    "def score(model, val):\n",
    "    X, y = [], []\n",
    "    for batch in val_dataset:\n",
    "        inputs, labels = batch\n",
    "        X.append(inputs)\n",
    "        y.append(labels)\n",
    "    # 각 입력 키에 대해 데이터를 결합하여 numpy 배열로 변환\n",
    "    X = {key: np.concatenate([d[key].numpy() for d in X], axis=0) for key in X[0].keys()}\n",
    "    y = np.concatenate(y, axis=0)\n",
    "    \n",
    "    # 실제 예측값 생성\n",
    "    real_predictions = model.predict(X)\n",
    "    logits = real_predictions.logits\n",
    "\n",
    "    # 예측값을 레이블로 변환\n",
    "    if logits.ndim > 1:\n",
    "        real_predicted_labels = np.argmax(logits, axis=1)\n",
    "    else:\n",
    "        real_predicted_labels = (logits > 0.5).astype(int)\n",
    "    \n",
    "\n",
    "    # 정확도 계산\n",
    "    real_accuracy = accuracy_score(y, real_predicted_labels)\n",
    "    print(f\"Real Accuracy: {real_accuracy:.4f}\")\n",
    "\n",
    "    # 분류 보고서 생성\n",
    "    real_report = classification_report(y, real_predicted_labels, target_names=[f\"Class {i}\" for i in range(logits.shape[1])])\n",
    "    print(real_report)\n",
    "\n",
    "    # F1 스코어 계산\n",
    "    real_f1 = f1_score(y, real_predicted_labels, average='weighted')\n",
    "    print(f\"\\nWeighted F1 Score (based on real predictions): {real_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "23b0c907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real Accuracy: 0.8861\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.85      0.84      0.85       196\n",
      "     Class 1       0.79      0.87      0.83       219\n",
      "     Class 2       1.00      0.99      0.99       176\n",
      "     Class 3       0.96      0.92      0.94       196\n",
      "     Class 4       0.86      0.82      0.84       179\n",
      "\n",
      "    accuracy                           0.89       966\n",
      "   macro avg       0.89      0.89      0.89       966\n",
      "weighted avg       0.89      0.89      0.89       966\n",
      "\n",
      "\n",
      "Weighted F1 Score (based on real predictions): 0.8869\n"
     ]
    }
   ],
   "source": [
    "score(model, val_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65902a5f",
   "metadata": {},
   "source": [
    "## 4. 모델 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "445ae6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_path =\"/aiffel/aiffel/dktc/data/test.json\"\n",
    "\n",
    "with open(test_data_path, \"r\", encoding=\"utf-8\") as json_file:\n",
    "    test = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "67daf3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "test_predict = list()\n",
    "\n",
    "for key in test:\n",
    "    test_sentence = test[key]['text']\n",
    "    \n",
    "    test_encodings = tokenizer(test_sentence, truncation=True, padding=True, max_length=300, return_tensors=\"tf\")\n",
    "    \n",
    "    test_predictions = model.predict({\n",
    "        \"input_ids\": test_encodings[\"input_ids\"],\n",
    "        \"token_type_ids\": test_encodings[\"token_type_ids\"],\n",
    "        \"attention_mask\": test_encodings[\"attention_mask\"]\n",
    "    }) \n",
    "    test_class_probabilities = tf.nn.softmax(test_predictions.logits, axis=-1).numpy() # [[0.13297564 0.8358507  0.00801584 0.02315779]]\n",
    "    test_predicted_class = np.argmax(test_class_probabilities, axis=1) # [ 1 ]\n",
    "    test_predict.append(test_predicted_class[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ea9f0420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 2)\n",
      "  file_name  class\n",
      "0     t_000      1\n",
      "1     t_001      2\n",
      "2     t_002      2\n",
      "3     t_003      3\n",
      "4     t_004      3\n"
     ]
    }
   ],
   "source": [
    "# {'협박 대화': 4, '갈취 대화': 0, '직장 내 괴롭힘 대화': 3, '기타 괴롭힘 대화': 1, '일반 대화': 2}\n",
    "#   협박 대화 : 0,  갈취 대화 : 1,  직장 내 괴롭힘 대화 : 2,  기타 괴롭힘 대화 : 3,  일반 대화 : 4\n",
    "def labelnum_to_text(x):\n",
    "    if x == 0:\n",
    "        return '01'\n",
    "    if x == 1:\n",
    "        return '03'\n",
    "    if x == 2:\n",
    "        return '04'\n",
    "    if x == 3:\n",
    "        return '02'\n",
    "    if x == 4:\n",
    "        return '00'\n",
    "\n",
    "import datetime\n",
    "    \n",
    "submission = pd.read_csv(\"../data/new_submission.csv\")\n",
    "submission[\"class\"] = [ labelnum_to_text(pred) for pred in test_predict ]\n",
    "\n",
    "now = datetime.datetime.now()\n",
    "filename = now.strftime(\"../sub/submission %y-%m-%d %H:%M.csv\")\n",
    "\n",
    "submission.to_csv(filename, index=False)\n",
    "submit_file = pd.read_csv(filename)\n",
    "\n",
    "print(submit_file.shape)\n",
    "print(submit_file.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2e8e6c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# submission 0.658"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
