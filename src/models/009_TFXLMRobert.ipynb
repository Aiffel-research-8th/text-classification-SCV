{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "603d08b1",
   "metadata": {},
   "source": [
    "## 0. 라이브러리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "dff4c1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "#from transformers import BertTokenizer, TFBertForSequenceClassification\n",
    "from transformers import XLMRobertaTokenizer, TFXLMRobertaModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import json\n",
    "from soynlp.normalizer import *\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4255fb85",
   "metadata": {},
   "source": [
    "## 1. 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0dc47e21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>conversation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>idx</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>일반 대화</td>\n",
       "      <td>야 여행 가기 너무 좋은 날씨다\\n날씨 진짜 너무 좋아 **이는 일하기 싫을 날씨야...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>갈취 대화</td>\n",
       "      <td>사정이 있었어요 . 살려주세요 . 뒤진 사람들 중에 사정 없는 사람 없어 맞아 . ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>갈취 대화</td>\n",
       "      <td>배고프다 그러게 야 만원만 빌려줘봐 오늘도 ? 저번에도 만원 빌려가고 안 돌려 줬잖...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>갈취 대화</td>\n",
       "      <td>저기 실례지만 제가 휠체어를 타는 장애인이라서 아 혼자 휠체어 운전하시는게 어렵다고...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>직장 내 괴롭힘 대화</td>\n",
       "      <td>김 사원 낙하산이라는 소문이 있던데 ? 요즘 시대에도 낙하산이 있어요 ? 요즘 더 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4826</th>\n",
       "      <td>일반 대화</td>\n",
       "      <td>티비는 잘 안 보니?\\n티비 매일 보지\\n너는?\\n키키 요즘 핫한 스우파 안 보니?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4827</th>\n",
       "      <td>갈취 대화</td>\n",
       "      <td>이거 나이키 신상이네 ? 응 아빠가 사주셨어 우와 멋지네 근데 너랑은 별로 안어울린...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4828</th>\n",
       "      <td>직장 내 괴롭힘 대화</td>\n",
       "      <td>일처리를 어떻게 한거야 ! 기간 내에 상품이 못오면 그사이 손실은 어떻게 할거냐고 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4829</th>\n",
       "      <td>직장 내 괴롭힘 대화</td>\n",
       "      <td>어우 정대리 이번에도 참 글래머 스럽게 입고왔네 네 ? 지금 저한태 하신말이세요 ?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4830</th>\n",
       "      <td>협박 대화</td>\n",
       "      <td>전화 좀 그만하세요 . 당신이 배달앱 리뷰에 내 욕을 써놔서 내가 잘 다니던 직장에...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4830 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            class                                       conversation\n",
       "idx                                                                 \n",
       "1           일반 대화  야 여행 가기 너무 좋은 날씨다\\n날씨 진짜 너무 좋아 **이는 일하기 싫을 날씨야...\n",
       "2           갈취 대화  사정이 있었어요 . 살려주세요 . 뒤진 사람들 중에 사정 없는 사람 없어 맞아 . ...\n",
       "3           갈취 대화  배고프다 그러게 야 만원만 빌려줘봐 오늘도 ? 저번에도 만원 빌려가고 안 돌려 줬잖...\n",
       "4           갈취 대화  저기 실례지만 제가 휠체어를 타는 장애인이라서 아 혼자 휠체어 운전하시는게 어렵다고...\n",
       "5     직장 내 괴롭힘 대화  김 사원 낙하산이라는 소문이 있던데 ? 요즘 시대에도 낙하산이 있어요 ? 요즘 더 ...\n",
       "...           ...                                                ...\n",
       "4826        일반 대화  티비는 잘 안 보니?\\n티비 매일 보지\\n너는?\\n키키 요즘 핫한 스우파 안 보니?...\n",
       "4827        갈취 대화  이거 나이키 신상이네 ? 응 아빠가 사주셨어 우와 멋지네 근데 너랑은 별로 안어울린...\n",
       "4828  직장 내 괴롭힘 대화  일처리를 어떻게 한거야 ! 기간 내에 상품이 못오면 그사이 손실은 어떻게 할거냐고 ...\n",
       "4829  직장 내 괴롭힘 대화  어우 정대리 이번에도 참 글래머 스럽게 입고왔네 네 ? 지금 저한태 하신말이세요 ?...\n",
       "4830        협박 대화  전화 좀 그만하세요 . 당신이 배달앱 리뷰에 내 욕을 써놔서 내가 잘 다니던 직장에...\n",
       "\n",
       "[4830 rows x 2 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_path =\"~/aiffel/dktc/data2/train0.csv\"\n",
    "train_data = pd.read_csv(train_data_path,index_col=0)\n",
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec70478",
   "metadata": {},
   "source": [
    "## 2. 데이터 준비 (Data preparation)\n",
    "### 2.1-1 전처리 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e443affb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentence(sentence):\n",
    "    # synolp\n",
    "    emoticon_normalize(sentence)\n",
    "    repeat_normalize(sentence)\n",
    "    sentence = re.sub(r'[^\\w\\s]', '', sentence)\n",
    "    # base preprocess\n",
    "    sentence = re.sub(r'([^a-zA-Zㄱ-ㅎ가-힣?.!,])', \" \", sentence)\n",
    "    sentence = re.sub(r'!+', '!', sentence)\n",
    "    sentence = re.sub(r'\\?+', '?', sentence)\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
    "    # 엔터 구분 (\\n)\n",
    "    sentence = sentence.replace(\"\\n\", \" \")\n",
    "    sentence = sentence.strip()\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374e80d0",
   "metadata": {},
   "source": [
    "### 2.1-2 전처리 함수 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3b334d60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4830/4830 [00:01<00:00, 3255.64it/s]\n"
     ]
    }
   ],
   "source": [
    "sentences = [preprocess_sentence(val) for val in tqdm(train_data['conversation'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b0a465",
   "metadata": {},
   "source": [
    "### 2.2 최대 길이 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7e8fe253",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf2eb43",
   "metadata": {},
   "source": [
    "### 2.3 class(label) 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4280ceea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "CLASS_NAMES = ['협박 대화', '갈취 대화', '직장 내 괴롭힘 대화', '기타 괴롭힘 대화', '일반 대화']\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(CLASS_NAMES)\n",
    "train_data['class'] = encoder.transform(train_data['class'])\n",
    "labels = train_data['class']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c293d5cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class mapping: {'협박 대화': 4, '갈취 대화': 0, '직장 내 괴롭힘 대화': 3, '기타 괴롭힘 대화': 1, '일반 대화': 2}\n"
     ]
    }
   ],
   "source": [
    "class_mapping = {class_name: encoder.transform([class_name])[0] for class_name in CLASS_NAMES}\n",
    "print(\"Class mapping:\", class_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133d9c52",
   "metadata": {},
   "source": [
    "### 2.4 train-val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5e66bf28",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentences, val_sentences, train_labels, val_labels = train_test_split(\n",
    "    sentences, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15f0d3b",
   "metadata": {},
   "source": [
    "## 3. 모델\n",
    "### 3.1-1 토크나이저 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f6800c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BERT 토크나이저와 모델 준비\n",
    "tokenizer = XLMRobertaTokenizer.from_pretrained('xlm-roberta-base')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1451b63",
   "metadata": {},
   "source": [
    "### 3.1-2 토크나이저 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3388e0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋을 BERT 입력 형식으로 변환\n",
    "train_encodings = tokenizer(train_sentences, truncation=True, padding=True, max_length=MAX_LEN)\n",
    "val_encodings = tokenizer(val_sentences, truncation=True, padding=True, max_length=MAX_LEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950f6e0b",
   "metadata": {},
   "source": [
    "### 3.2 모델 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "71e60134",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = TFXLMRobertaModel.from_pretrained('xlm-roberta-base', num_labels=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9532ce9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFXLMRobertaModel.\n",
      "\n",
      "All the layers of TFXLMRobertaModel were initialized from the model checkpoint at xlm-roberta-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFXLMRobertaModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "input_ids = Input(shape=(MAX_LEN,), dtype=tf.int32, name='input_ids')\n",
    "attention_mask = Input(shape=(MAX_LEN,), dtype=tf.int32, name='attention_mask')\n",
    "roberta_model = TFXLMRobertaModel.from_pretrained('xlm-roberta-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f0c6c5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the output of the XLM-RoBERTa model\n",
    "sequence_output = roberta_model(input_ids, attention_mask=attention_mask)[0]\n",
    "\n",
    "# Extract the CLS token (the first token in the sequence)\n",
    "cls_token = sequence_output[:, 0, :]\n",
    "\n",
    "# Add a dense layer with softmax activation for classification\n",
    "output_layer = Dense(300, activation='softmax')(cls_token)\n",
    "\n",
    "# Define the model\n",
    "model = tf.keras.Model(inputs=[input_ids, attention_mask], outputs=output_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ca313a",
   "metadata": {},
   "source": [
    "### 3.3 파라미터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "27887d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 8\n",
    "lr = 5e-5\n",
    "EPOCH = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a421ca3d",
   "metadata": {},
   "source": [
    "### 3.4 TF 데이터셋 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b81ee97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    {'input_ids': train_encodings['input_ids'], 'attention_mask': train_encodings['attention_mask']},\n",
    "    train_labels\n",
    ")).shuffle(100).batch(BATCH_SIZE)\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    {'input_ids': val_encodings['input_ids'], 'attention_mask': val_encodings['attention_mask']},\n",
    "    val_labels\n",
    ")).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b52d2b",
   "metadata": {},
   "source": [
    "### 3.5 모델 컴파일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a290a6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb8bc77",
   "metadata": {},
   "source": [
    "### 3.6 모델 훈련"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a93e11",
   "metadata": {},
   "source": [
    "### 3.6-1 콜백 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "cf27a88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=2,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath='best_model_weights.h5',\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True,\n",
    "    mode='min',\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72abc053",
   "metadata": {},
   "source": [
    "### 3.6-2 모델 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5d7e2c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#풀러 레이어가 고정되지 않았으며 올바르게 연결되었는지 확인하세요. 모든 레이어를 고정 해제하는 방법은 다음과 같습니다.\n",
    "for layer in model.layers:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3d4dbc8b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/keras/backend.py:4906: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['tfxlm_roberta_model_7/roberta/pooler/dense/kernel:0', 'tfxlm_roberta_model_7/roberta/pooler/dense/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tfxlm_roberta_model_7/roberta/pooler/dense/kernel:0', 'tfxlm_roberta_model_7/roberta/pooler/dense/bias:0'] when minimizing the loss.\n",
      "483/483 [==============================] - 334s 662ms/step - loss: 1.2592 - accuracy: 0.5158 - val_loss: 0.6933 - val_accuracy: 0.7609\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.69331, saving model to best_model_weights.h5\n",
      "Epoch 2/10\n",
      "483/483 [==============================] - 316s 655ms/step - loss: 0.5426 - accuracy: 0.8144 - val_loss: 0.5667 - val_accuracy: 0.8168\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.69331 to 0.56669, saving model to best_model_weights.h5\n",
      "Epoch 3/10\n",
      "483/483 [==============================] - 316s 654ms/step - loss: 0.3852 - accuracy: 0.8742 - val_loss: 0.4356 - val_accuracy: 0.8716\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.56669 to 0.43556, saving model to best_model_weights.h5\n",
      "Epoch 4/10\n",
      "483/483 [==============================] - 316s 654ms/step - loss: 1.3364 - accuracy: 0.3944 - val_loss: 1.3000 - val_accuracy: 0.3830\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.43556\n",
      "Epoch 5/10\n",
      "483/483 [==============================] - 315s 653ms/step - loss: 1.0577 - accuracy: 0.5225 - val_loss: 1.2474 - val_accuracy: 0.3975\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.43556\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f758d21a340>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=EPOCH,\n",
    "    callbacks=[early_stopping, checkpoint]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cda8a64",
   "metadata": {},
   "source": [
    "### 3.7 모델 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f597c1ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121/121 [==============================] - 22s 181ms/step - loss: 0.4356 - accuracy: 0.8716\n",
      "평가 결과: [0.43555948138237, 0.8716356158256531]\n"
     ]
    }
   ],
   "source": [
    "# 모델 평가\n",
    "evaluation = model.evaluate(val_dataset)\n",
    "print(\"평가 결과:\", evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f6db5981",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, f1_score, confusion_matrix, accuracy_score\n",
    "\n",
    "def score(model, val_dataset):\n",
    "    X, y = [], []\n",
    "    for batch in val_dataset:\n",
    "        inputs, labels = batch\n",
    "        X.append(inputs)\n",
    "        y.append(labels)\n",
    "    X = {key: np.concatenate([d[key].numpy() for d in X], axis=0) for key in X[0].keys()}\n",
    "    y = np.concatenate(y, axis=0)\n",
    "    \n",
    "    real_predictions = model.predict(X)\n",
    "    logits = real_predictions\n",
    "\n",
    "    if logits.ndim > 1:\n",
    "        real_predicted_labels = np.argmax(logits, axis=1)\n",
    "    else:\n",
    "        real_predicted_labels = (logits > 0.5).astype(int)\n",
    "    \n",
    "    real_accuracy = accuracy_score(y, real_predicted_labels)\n",
    "    print(f\"Real Accuracy: {real_accuracy:.4f}\")\n",
    "\n",
    "    real_report = classification_report(y, real_predicted_labels, target_names=[f\"Class {i}\" for i in range(5)])\n",
    "    print(real_report)\n",
    "\n",
    "    real_f1 = f1_score(y, real_predicted_labels, average='weighted')\n",
    "    print(f\"\\nWeighted F1 Score (based on real predictions): {real_f1:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "66fa49fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real Accuracy: 0.8716\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.85      0.81      0.83       175\n",
      "     Class 1       0.73      0.89      0.80       215\n",
      "     Class 2       0.99      0.96      0.97       178\n",
      "     Class 3       0.93      0.94      0.93       201\n",
      "     Class 4       0.93      0.76      0.84       197\n",
      "\n",
      "    accuracy                           0.87       966\n",
      "   macro avg       0.89      0.87      0.87       966\n",
      "weighted avg       0.88      0.87      0.87       966\n",
      "\n",
      "\n",
      "Weighted F1 Score (based on real predictions): 0.8729\n"
     ]
    }
   ],
   "source": [
    "score(model, val_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b01f081",
   "metadata": {},
   "source": [
    "## 4. 모델 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "be727c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "test_data_path = \"/aiffel/aiffel/dktc/data/test.json\"\n",
    "test = pd.read_json(test_data_path).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7f3d3dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "test_predict = []\n",
    "\n",
    "for idx, value in test.iterrows():\n",
    "\n",
    "    test_sentence = value[\"text\"]\n",
    "    \n",
    "    test_encodings = tokenizer(test_sentence, truncation=True, padding=\"max_length\", max_length=MAX_LEN, return_tensors=\"tf\")\n",
    "\n",
    "    test_predictions = model.predict(\n",
    "        (test_encodings[\"input_ids\"],\n",
    "         test_encodings[\"attention_mask\"])\n",
    "    )\n",
    "    test_class_probabilities = tf.nn.softmax(test_predictions, axis=-1).numpy() # [[0.13297564 0.8358507  0.00801584 0.02315779]]\n",
    "    test_predicted_class = np.argmax(test_class_probabilities, axis=1) # [ 1 ]\n",
    "    test_predict.append(test_predicted_class[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d35d6135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 2)\n",
      "  file_name  class\n",
      "0     t_000      1\n",
      "1     t_001      2\n",
      "2     t_002      3\n",
      "3     t_003      3\n",
      "4     t_004      3\n"
     ]
    }
   ],
   "source": [
    "# {'협박 대화': 4, '갈취 대화': 0, '직장 내 괴롭힘 대화': 3, '기타 괴롭힘 대화': 1, '일반 대화': 2}\n",
    "#   협박 대화 : 0,  갈취 대화 : 1,  직장 내 괴롭힘 대화 : 2,  기타 괴롭힘 대화 : 3,  일반 대화 : 4\n",
    "def labelnum_to_text(x):\n",
    "    if x == 0:\n",
    "        return '01'\n",
    "    if x == 1:\n",
    "        return '03'\n",
    "    if x == 2:\n",
    "        return '04'\n",
    "    if x == 3:\n",
    "        return '02'\n",
    "    if x == 4:\n",
    "        return '00'\n",
    "\n",
    "import datetime\n",
    "    \n",
    "submission = pd.read_csv(\"/aiffel/aiffel/dktc/data/new_submission.csv\")\n",
    "submission[\"class\"] = [ labelnum_to_text(pred) for pred in test_predict ]\n",
    "\n",
    "now = datetime.datetime.now()\n",
    "filename = now.strftime(\"submission %y-%m-%d %H:%M.csv\")\n",
    "\n",
    "submission.to_csv(filename, index=False)\n",
    "submit_file = pd.read_csv(filename)\n",
    "\n",
    "print(submit_file.shape)\n",
    "print(submit_file.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3216d25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('~/aiffel/dktc/data2/submission_0.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
