{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "# import tensorflow as tf\n",
    "import tensorflow\n",
    "\n",
    "# pip install tf-keras 설치 필요\n",
    "\n",
    "from transformers import BertTokenizer, TFBertForSequenceClassification\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "from soynlp.normalizer import *\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "# from tensorflow.keras.utils import plot_model\n",
    "# from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "# 메모리 해제\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>conversation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>idx</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>일반 대화</td>\n",
       "      <td>오늘 날씨 어때?\\n맑고 따뜻해.\\n좋네! 주말에 계획 있어?\\n등산 갈 생각이야....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>일반 대화</td>\n",
       "      <td>오늘 날씨 어때?\\n맑고 따뜻해.\\n좋네! 주말에 계획 있어?\\n등산 갈 생각이야....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>기타 괴롭힘 대화</td>\n",
       "      <td>너 피아노 좀 쳐봐.\\n싫어.\\n왜 손가락 없다고 유세 떠는 거야?\\n이씨.\\n비행...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>갈취 대화</td>\n",
       "      <td>요즘에는 액수가 작네?\\n미안해 요즘에 용돈이 작아\\n그게 나랑 무슨 상관이야?\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>기타 괴롭힘 대화</td>\n",
       "      <td>야 이거봐 완전 길동이 닯음\\n 진짜네 \\n야 그러지마.\\n왜 똑같구만 원숭이 \\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4946</th>\n",
       "      <td>직장 내 괴롭힘 대화</td>\n",
       "      <td>어이 신병.\\n이병 김범례.\\n와봐.\\n네.\\n네? 뒤질래?\\n.자.잘못들었습니다?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4947</th>\n",
       "      <td>직장 내 괴롭힘 대화</td>\n",
       "      <td>오늘 회의 안건인 길동프로그램의 출연자는 누구로 할 것인가에 대해 모두 의견 내주시...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4948</th>\n",
       "      <td>직장 내 괴롭힘 대화</td>\n",
       "      <td>야 열심히들 해라 새끼들아\\n넵 감사해요 부장님\\n야 내가 언제 너 한테 말했냐\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4949</th>\n",
       "      <td>일반 대화</td>\n",
       "      <td>오늘 날씨 어때?\\n맑고 따뜻해.\\n좋네! 주말에 계획 있어?\\n등산 갈 생각이야....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4950</th>\n",
       "      <td>직장 내 괴롭힘 대화</td>\n",
       "      <td>야 신입 여기 와 봐.\\n네?\\n이게 선배가 부르는데 말꼬리 올려? 너 커피 탈 줄...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4950 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            class                                       conversation\n",
       "idx                                                                 \n",
       "1           일반 대화  오늘 날씨 어때?\\n맑고 따뜻해.\\n좋네! 주말에 계획 있어?\\n등산 갈 생각이야....\n",
       "2           일반 대화  오늘 날씨 어때?\\n맑고 따뜻해.\\n좋네! 주말에 계획 있어?\\n등산 갈 생각이야....\n",
       "3       기타 괴롭힘 대화  너 피아노 좀 쳐봐.\\n싫어.\\n왜 손가락 없다고 유세 떠는 거야?\\n이씨.\\n비행...\n",
       "4           갈취 대화  요즘에는 액수가 작네?\\n미안해 요즘에 용돈이 작아\\n그게 나랑 무슨 상관이야?\\n...\n",
       "5       기타 괴롭힘 대화  야 이거봐 완전 길동이 닯음\\n 진짜네 \\n야 그러지마.\\n왜 똑같구만 원숭이 \\n...\n",
       "...           ...                                                ...\n",
       "4946  직장 내 괴롭힘 대화  어이 신병.\\n이병 김범례.\\n와봐.\\n네.\\n네? 뒤질래?\\n.자.잘못들었습니다?...\n",
       "4947  직장 내 괴롭힘 대화  오늘 회의 안건인 길동프로그램의 출연자는 누구로 할 것인가에 대해 모두 의견 내주시...\n",
       "4948  직장 내 괴롭힘 대화  야 열심히들 해라 새끼들아\\n넵 감사해요 부장님\\n야 내가 언제 너 한테 말했냐\\n...\n",
       "4949        일반 대화  오늘 날씨 어때?\\n맑고 따뜻해.\\n좋네! 주말에 계획 있어?\\n등산 갈 생각이야....\n",
       "4950  직장 내 괴롭힘 대화  야 신입 여기 와 봐.\\n네?\\n이게 선배가 부르는데 말꼬리 올려? 너 커피 탈 줄...\n",
       "\n",
       "[4950 rows x 2 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_path = \"./data/train2.csv\"\n",
    "train_data = pd.read_csv(train_data_path, index_col=0)\n",
    "train_data\n",
    "\n",
    "# train_data_path =\"/aiffel/aiffel/dktc/data/train.csv\"\n",
    "# train_data = pd.read_csv(train_data_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generate sentences..: 100%|██████████| 4950/4950 [00:01<00:00, 4644.23it/s]\n",
      "class label convert to num...: 100%|██████████| 4950/4950 [00:00<00:00, 1651694.89it/s]\n"
     ]
    }
   ],
   "source": [
    "# 영어, 한국어가 아닌 경우 공백 ( ) 처리\n",
    "# 두 개 이상의 느낌표(!+)가 있을 경우 느낌표 하나로 처리\n",
    "# 두 개 이상의 물음표(\\?+)가 있을 경우 물음표 하나로 처리\n",
    "# ?, ., !, , 가 있을 경우 그 주위에 공백을 추가\n",
    "# 연속적인 공백이 있을 시 공백을 하나로 처리\n",
    "# 문장 앞뒤의 공백과 개행문자를 제거(strip)\n",
    "\n",
    "\n",
    "def preprocess_sentence(sentence):\n",
    "    emoticon_normalize(sentence)\n",
    "    repeat_normalize(sentence)\n",
    "    sentence = re.sub(r\"([^a-zA-Zㄱ-ㅎ가-힣?.!,])\", \" \", sentence)\n",
    "    sentence = re.sub(r\"!+\", \"!\", sentence)\n",
    "    sentence = re.sub(r\"\\?+\", \"?\", sentence)\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
    "    sentence = sentence.strip()\n",
    "    return sentence\n",
    "\n",
    "\n",
    "# 영어, 한국어가 아닌 경우 공백 ( ) 처리\n",
    "# 연속적인 공백이 있을 시 공백을 하나로 처리\n",
    "# 문장 앞뒤의 공백과 개행문자를 제거(strip)\n",
    "# 위 함수를 거친 문장은 문법기호(?, !, , 등)도 모두 제거됨\n",
    "def preprocess_sentence2(sentence):\n",
    "    emoticon_normalize(sentence)\n",
    "    repeat_normalize(sentence)\n",
    "    sentence = re.sub(r\"([^a-zA-Zㄱ-ㅎ가-힣])\", \" \", sentence)\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
    "    sentence = sentence.strip()\n",
    "    return sentence\n",
    "\n",
    "\n",
    "# 학습할 문장이 담길 배열\n",
    "sentences = []\n",
    "\n",
    "for val in tqdm(train_data[\"conversation\"], desc=\"Generate sentences..\"):\n",
    "    # preprocess_sentence2()로 문장(val)을 전처리하여 배열에 저장\n",
    "    sentences.append(preprocess_sentence2(val))\n",
    "\n",
    "\n",
    "#### preprocess_sentence() 케이스 사용 시 해당 함수 내용을 써보자\n",
    "#### 테스트는 preprocess_sentence()를 거친 데이터 기준으로 수행됨\n",
    "def dummy():\n",
    "    # 학습할 문장이 담길 배열\n",
    "    sentences2 = []\n",
    "\n",
    "    for val in tqdm(train_data[\"conversation\"], desc=\"Generate sentences..\"):\n",
    "        # preprocess_sentence()로 문장(val)을 전처리하여 배열에 저장\n",
    "        sentences.append(preprocess_sentence(val))\n",
    "\n",
    "\n",
    "labels = []\n",
    "\n",
    "for val in tqdm(train_data[\"class\"], desc=\"class label convert to num...\"):\n",
    "    if \"갈취\" in val:\n",
    "        labels.append(1)\n",
    "    if \"기타\" in val:\n",
    "        labels.append(3)\n",
    "    if \"직장\" in val:\n",
    "        labels.append(2)\n",
    "    if \"협박\" in val:\n",
    "        labels.append(0)\n",
    "    ######################################################\n",
    "    if \"일반\" in val:\n",
    "        labels.append(4)\n",
    "\n",
    "\n",
    "# 데이터셋 분할\n",
    "train_sentences, val_sentences, train_labels, val_labels = train_test_split(\n",
    "    sentences, labels, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "def random_deletion(words, p=0.3):\n",
    "    if len(words) == 1:\n",
    "        return words\n",
    "\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        r = random.uniform(0, 1)\n",
    "        if r > p:\n",
    "            new_words.append(word)\n",
    "\n",
    "    if len(new_words) == 0:\n",
    "        rand_int = random.randint(0, len(words) - 1)\n",
    "        return [words[rand_int]]\n",
    "\n",
    "    return \"\".join(new_words)\n",
    "\n",
    "\n",
    "def swap_word(new_words):\n",
    "    random_idx_1 = random.randint(0, len(new_words) - 1)\n",
    "    random_idx_2 = random_idx_1\n",
    "    counter = 0\n",
    "\n",
    "    while random_idx_2 == random_idx_1:\n",
    "        random_idx_2 = random.randint(0, len(new_words) - 1)\n",
    "        counter += 1\n",
    "        if counter > 3:\n",
    "            return new_words\n",
    "\n",
    "    new_words[random_idx_1], new_words[random_idx_2] = (\n",
    "        new_words[random_idx_2],\n",
    "        new_words[random_idx_1],\n",
    "    )\n",
    "    return new_words\n",
    "\n",
    "\n",
    "def random_swap(words, n=3):\n",
    "    new_words = words.copy()\n",
    "    for _ in range(n):\n",
    "        new_words = swap_word(new_words)\n",
    "\n",
    "    return new_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before data augmentation:  3960\n",
      "after data augmentation:  3960\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>오늘 날씨 어때 맑고 따뜻해 좋네 주말에 계획 있어 등산 갈 생각이야 재밌겠다 최근...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>사장님 배달이 분까지인데 분이나 늦었잖아요 죄송합니다 배달원한테 전달을 했는데 길이...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>이번 달 월급 들어오면 갚는다며 들어오자마자 다 뜯겨서 그래 미안해 그 말이 벌써 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>야 우리 내일 현장학습인 거 알지 응 알지 그럼 니가 내 대신 내도시락도 좀 싸와라...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>여기가 어딘가요 야 있는 돈 다 내놔 맞기 싫으면 아니 댁은 누구신대 다짜고짜 이러...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3955</th>\n",
       "      <td>야 일 제대로 안해 아니 물량수준이 희망사항 수준인데 그래서 뭐 임마 그 많은 작업...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3956</th>\n",
       "      <td>역시 난 니가 올 줄 알았어 우리가족을 인질로 잡아 니가 그러고도 사람이야 당연하지...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3957</th>\n",
       "      <td>밤마다 뭘하는 지 시끄러워서 잠을 못자겠다고 밤에 뭐 하긴 자지 자는 데 왜 쿵쾅거...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3958</th>\n",
       "      <td>오늘 날씨 어때 맑고 따뜻해 좋네 주말에 계획 있어 등산 갈 생각이야 재밌겠다 최근...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3959</th>\n",
       "      <td>아 운전 똑바로 하셔야죠 죄송해요이걸 어쩌지 차 다 긁혔잖아요 일단 보험사 부를까요...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3960 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sentence  class\n",
       "0     오늘 날씨 어때 맑고 따뜻해 좋네 주말에 계획 있어 등산 갈 생각이야 재밌겠다 최근...      4\n",
       "1     사장님 배달이 분까지인데 분이나 늦었잖아요 죄송합니다 배달원한테 전달을 했는데 길이...      3\n",
       "2     이번 달 월급 들어오면 갚는다며 들어오자마자 다 뜯겨서 그래 미안해 그 말이 벌써 ...      1\n",
       "3     야 우리 내일 현장학습인 거 알지 응 알지 그럼 니가 내 대신 내도시락도 좀 싸와라...      3\n",
       "4     여기가 어딘가요 야 있는 돈 다 내놔 맞기 싫으면 아니 댁은 누구신대 다짜고짜 이러...      1\n",
       "...                                                 ...    ...\n",
       "3955  야 일 제대로 안해 아니 물량수준이 희망사항 수준인데 그래서 뭐 임마 그 많은 작업...      2\n",
       "3956  역시 난 니가 올 줄 알았어 우리가족을 인질로 잡아 니가 그러고도 사람이야 당연하지...      0\n",
       "3957  밤마다 뭘하는 지 시끄러워서 잠을 못자겠다고 밤에 뭐 하긴 자지 자는 데 왜 쿵쾅거...      0\n",
       "3958  오늘 날씨 어때 맑고 따뜻해 좋네 주말에 계획 있어 등산 갈 생각이야 재밌겠다 최근...      4\n",
       "3959  아 운전 똑바로 하셔야죠 죄송해요이걸 어쩌지 차 다 긁혔잖아요 일단 보험사 부를까요...      1\n",
       "\n",
       "[3960 rows x 2 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"before data augmentation: \", len(train_sentences))\n",
    "\n",
    "train_splted = pd.DataFrame({\"sentence\": train_sentences, \"class\": train_labels})\n",
    "# random deletion\n",
    "train_splted_rd = train_splted.copy()\n",
    "train_splted_rd[\"sentence\"] = train_splted_rd[\"sentence\"].apply(random_deletion)\n",
    "\n",
    "# random swap\n",
    "train_splted_rs = train_splted.copy()\n",
    "train_splted_rs[\"sentence\"] = random_swap(train_splted_rs[\"sentence\"])\n",
    "\n",
    "# with data augmentation\n",
    "# train_concated = pd.concat([train_splted,train_splted_rd,train_splted_rs])\n",
    "\n",
    "# without data augmentation\n",
    "train_concated = pd.concat([train_splted])\n",
    "\n",
    "print(\"after data augmentation: \", len(train_concated))\n",
    "\n",
    "train_concated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_sentences = list(train_concated['sentence'].values)\n",
    "# train_labels = list(train_concated['class'].values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# BERT 토크나이저 & 모델 준비\n",
    "# 학습된 BERT 모델 사용 → bert-base-multilingual-cased\n",
    "\n",
    "# BERT 토크나이저와 모델 준비\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-multilingual-cased\")\n",
    "model = TFBertForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-multilingual-cased\", num_labels=5\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 토큰 최대 길이\n",
    "MAX_LEN = 200\n",
    "# 데이터 묶음 크기\n",
    "BATCH_SIZE = 32\n",
    "# Learning Rate\n",
    "lr = 5e-5  # 5e-5 , 1e-4\n",
    "# 훈련 횟수\n",
    "EPOCH = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋을 BERT 입력 형식으로 변환\n",
    "train_encodings = tokenizer(\n",
    "    train_sentences, truncation=True, padding=True, max_length=MAX_LEN\n",
    ")  # 뒤쪽에 패딩\n",
    "val_encodings = tokenizer(\n",
    "    val_sentences, truncation=True, padding=True, max_length=MAX_LEN\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorFlow 데이터셋 생성\n",
    "train_dataset = (\n",
    "    tensorflow.data.Dataset.from_tensor_slices((dict(train_encodings), train_labels))\n",
    "    .shuffle(100)\n",
    "    .batch(BATCH_SIZE)\n",
    ")\n",
    "\n",
    "val_dataset = tensorflow.data.Dataset.from_tensor_slices(\n",
    "    (dict(val_encodings), val_labels)\n",
    ").batch(BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.3.3\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "\n",
    "print(keras.__version__)\n",
    "\n",
    "# import os\n",
    "# os.environ[\"TF_USE_LEGACY_KERAS\"] = \"1\"\n",
    "\n",
    "opt = tensorflow.compat.v1.train.AdamOptimizer(learning_rate=lr)\n",
    "# opt = keras.optimizers.Adam(learning_rate=lr)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=opt,\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ReduceLROnPlateau' object has no attribute '_implements_train_batch_hooks'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[72], line 12\u001b[0m\n\u001b[0;32m      2\u001b[0m reduce_lr \u001b[38;5;241m=\u001b[39m tensorflow\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mReduceLROnPlateau(\n\u001b[0;32m      3\u001b[0m     monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m,  \u001b[38;5;66;03m# 모니터링할 지표 (검증 정확도)\u001b[39;00m\n\u001b[0;32m      4\u001b[0m     factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m,\n\u001b[0;32m      5\u001b[0m     patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,\n\u001b[0;32m      6\u001b[0m     min_lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-6\u001b[39m,\n\u001b[0;32m      7\u001b[0m )\n\u001b[0;32m     10\u001b[0m epoch \u001b[38;5;241m=\u001b[39m EPOCH\n\u001b[1;32m---> 12\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mreduce_lr\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\thilllon\\git\\text-classification-SCV\\.venv\\lib\\site-packages\\transformers\\modeling_tf_utils.py:1229\u001b[0m, in \u001b[0;36mTFPreTrainedModel.fit\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1226\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(keras\u001b[38;5;241m.\u001b[39mModel\u001b[38;5;241m.\u001b[39mfit)\n\u001b[0;32m   1227\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m   1228\u001b[0m     args, kwargs \u001b[38;5;241m=\u001b[39m convert_batch_encoding(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m-> 1229\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfit(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\thilllon\\git\\text-classification-SCV\\.venv\\lib\\site-packages\\tf_keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\thilllon\\git\\text-classification-SCV\\.venv\\lib\\site-packages\\tf_keras\\src\\callbacks.py:245\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    237\u001b[0m \u001b[38;5;66;03m# Performance optimization: determines if batch hooks need to be called.\u001b[39;00m\n\u001b[0;32m    239\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_supports_tf_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mall\u001b[39m(\n\u001b[0;32m    240\u001b[0m     \u001b[38;5;28mgetattr\u001b[39m(cb, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_supports_tf_logs\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;28;01mfor\u001b[39;00m cb \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks\n\u001b[0;32m    241\u001b[0m )\n\u001b[0;32m    242\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_hooks_support_tf_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mall\u001b[39m(\n\u001b[0;32m    243\u001b[0m     \u001b[38;5;28mgetattr\u001b[39m(cb, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_supports_tf_logs\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    244\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m cb \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks\n\u001b[1;32m--> 245\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mcb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_implements_train_batch_hooks\u001b[49m()\n\u001b[0;32m    246\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m cb\u001b[38;5;241m.\u001b[39m_implements_test_batch_hooks()\n\u001b[0;32m    247\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m cb\u001b[38;5;241m.\u001b[39m_implements_predict_batch_hooks()\n\u001b[0;32m    248\u001b[0m )\n\u001b[0;32m    250\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_call_train_batch_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28many\u001b[39m(\n\u001b[0;32m    251\u001b[0m     cb\u001b[38;5;241m.\u001b[39m_implements_train_batch_hooks() \u001b[38;5;28;01mfor\u001b[39;00m cb \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks\n\u001b[0;32m    252\u001b[0m )\n\u001b[0;32m    253\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_call_test_batch_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28many\u001b[39m(\n\u001b[0;32m    254\u001b[0m     cb\u001b[38;5;241m.\u001b[39m_implements_test_batch_hooks() \u001b[38;5;28;01mfor\u001b[39;00m cb \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks\n\u001b[0;32m    255\u001b[0m )\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'ReduceLROnPlateau' object has no attribute '_implements_train_batch_hooks'"
     ]
    }
   ],
   "source": [
    "# 스케줄러 설정\n",
    "reduce_lr = tensorflow.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor=\"val_accuracy\",  # 모니터링할 지표 (검증 정확도)\n",
    "    factor=0.5,\n",
    "    patience=3,\n",
    "    min_lr=1e-6,\n",
    ")\n",
    "\n",
    "\n",
    "epoch = EPOCH\n",
    "\n",
    "model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=epoch,\n",
    "    callbacks=[reduce_lr],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "# 메모리 해제\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "# 모델 평가\n",
    "evaluation = model.evaluate(val_dataset)\n",
    "print(\"평가 결과:\", evaluation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
